{"ast":null,"code":"let conversationHistoryID = [{\n  role: \"system\",\n  content: ` A part ID is the letters PS followed by a series of numbers. If there was a part ID specified, give me that number. Respond with ONLY the relevant part ID number. If there is no part ID, respond with JUST the word NO`\n}];\nexport const getID = async userQuery => {\n  conversationHistoryID.push({\n    role: \"user\",\n    content: userQuery\n  });\n  const completion = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n    method: \"POST\",\n    headers: {\n      \"Content-Type\": \"application/json\",\n      \"Authorization\": 'Bearer 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'\n    },\n    body: JSON.stringify({\n      model: \"gpt-4o-mini\",\n      messages: conversationHistoryID\n    })\n  });\n  const data = await completion.json();\n  let get_response = data.choices[0].message.content;\n  console.log(\"part_id\");\n  console.log(get_response);\n  conversationHistoryID.push({\n    role: \"assistant\",\n    content: get_response\n  });\n  if (get_response == \"NO\") {\n    return null;\n  } else {\n    return get_response;\n  }\n};","map":{"version":3,"names":["conversationHistoryID","role","content","getID","userQuery","push","completion","fetch","method","headers","body","JSON","stringify","model","messages","data","json","get_response","choices","message","console","log"],"sources":["/Users/mayamagavi/instalily/case-study/src/api/getPartID.js"],"sourcesContent":["\nlet conversationHistoryID = [\n  { role: \"system\", content: ` A part ID is the letters PS followed by a series of numbers. If there was a part ID specified, give me that number. Respond with ONLY the relevant part ID number. If there is no part ID, respond with JUST the word NO` }\n];\n\nexport const getID = async (userQuery) => {\n\n  conversationHistoryID.push({ role: \"user\", content: userQuery });\n\n  const completion = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n    method: \"POST\",\n    headers: {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": 'Bearer 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',\n    },\n    body: JSON.stringify({\n        model: \"gpt-4o-mini\",\n        messages: conversationHistoryID\n    })\n  });\n\n  const data = await completion.json();\n  let get_response = data.choices[0].message.content;\n  console.log(\"part_id\")\n  console.log(get_response);\n  conversationHistoryID.push({ role: \"assistant\", content: get_response });\n\n  if (get_response == \"NO\") {\n    return null\n  } else {\n    return get_response\n  }\n};"],"mappings":"AACA,IAAIA,qBAAqB,GAAG,CAC1B;EAAEC,IAAI,EAAE,QAAQ;EAAEC,OAAO,EAAG;AAA2N,CAAC,CACzP;AAED,OAAO,MAAMC,KAAK,GAAG,MAAOC,SAAS,IAAK;EAExCJ,qBAAqB,CAACK,IAAI,CAAC;IAAEJ,IAAI,EAAE,MAAM;IAAEC,OAAO,EAAEE;EAAU,CAAC,CAAC;EAEhE,MAAME,UAAU,GAAG,MAAMC,KAAK,CAAC,4CAA4C,EAAE;IAC3EC,MAAM,EAAE,MAAM;IACdC,OAAO,EAAE;MACL,cAAc,EAAE,kBAAkB;MAClC,eAAe,EAAE;IACrB,CAAC;IACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;MACjBC,KAAK,EAAE,aAAa;MACpBC,QAAQ,EAAEd;IACd,CAAC;EACH,CAAC,CAAC;EAEF,MAAMe,IAAI,GAAG,MAAMT,UAAU,CAACU,IAAI,CAAC,CAAC;EACpC,IAAIC,YAAY,GAAGF,IAAI,CAACG,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,CAACjB,OAAO;EAClDkB,OAAO,CAACC,GAAG,CAAC,SAAS,CAAC;EACtBD,OAAO,CAACC,GAAG,CAACJ,YAAY,CAAC;EACzBjB,qBAAqB,CAACK,IAAI,CAAC;IAAEJ,IAAI,EAAE,WAAW;IAAEC,OAAO,EAAEe;EAAa,CAAC,CAAC;EAExE,IAAIA,YAAY,IAAI,IAAI,EAAE;IACxB,OAAO,IAAI;EACb,CAAC,MAAM;IACL,OAAOA,YAAY;EACrB;AACF,CAAC"},"metadata":{},"sourceType":"module","externalDependencies":[]}