{"ast":null,"code":"import { BaseChain } from \"./base.js\";\nimport { BasePromptTemplate } from \"../prompts/base.js\";\nimport { BaseLanguageModel } from \"../base_language/index.js\";\nimport { NoOpOutputParser } from \"../output_parsers/noop.js\";\n/**\n * Chain to run queries against LLMs.\n *\n * @example\n * ```ts\n * import { LLMChain } from \"langchain/chains\";\n * import { OpenAI } from \"langchain/llms/openai\";\n * import { PromptTemplate } from \"langchain/prompts\";\n *\n * const prompt = PromptTemplate.fromTemplate(\"Tell me a {adjective} joke\");\n * const llm = new LLMChain({ llm: new OpenAI(), prompt });\n * ```\n */\nexport class LLMChain extends BaseChain {\n  static lc_name() {\n    return \"LLMChain\";\n  }\n  get inputKeys() {\n    return this.prompt.inputVariables;\n  }\n  get outputKeys() {\n    return [this.outputKey];\n  }\n  constructor(fields) {\n    super(fields);\n    Object.defineProperty(this, \"lc_serializable\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: true\n    });\n    Object.defineProperty(this, \"prompt\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"llm\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"llmKwargs\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"outputKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: \"text\"\n    });\n    Object.defineProperty(this, \"outputParser\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    this.prompt = fields.prompt;\n    this.llm = fields.llm;\n    this.llmKwargs = fields.llmKwargs;\n    this.outputKey = fields.outputKey ?? this.outputKey;\n    this.outputParser = fields.outputParser ?? new NoOpOutputParser();\n    if (this.prompt.outputParser) {\n      if (fields.outputParser) {\n        throw new Error(\"Cannot set both outputParser and prompt.outputParser\");\n      }\n      this.outputParser = this.prompt.outputParser;\n    }\n  }\n  /** @ignore */\n  _selectMemoryInputs(values) {\n    const valuesForMemory = super._selectMemoryInputs(values);\n    for (const key of this.llm.callKeys) {\n      if (key in values) {\n        delete valuesForMemory[key];\n      }\n    }\n    return valuesForMemory;\n  }\n  /** @ignore */\n  async _getFinalOutput(generations, promptValue, runManager) {\n    let finalCompletion;\n    if (this.outputParser) {\n      finalCompletion = await this.outputParser.parseResultWithPrompt(generations, promptValue, runManager?.getChild());\n    } else {\n      finalCompletion = generations[0].text;\n    }\n    return finalCompletion;\n  }\n  /**\n   * Run the core logic of this chain and add to output if desired.\n   *\n   * Wraps _call and handles memory.\n   */\n  call(values, config) {\n    return super.call(values, config);\n  }\n  /** @ignore */\n  async _call(values, runManager) {\n    const valuesForPrompt = {\n      ...values\n    };\n    const valuesForLLM = {\n      ...this.llmKwargs\n    };\n    for (const key of this.llm.callKeys) {\n      if (key in values) {\n        valuesForLLM[key] = values[key];\n        delete valuesForPrompt[key];\n      }\n    }\n    const promptValue = await this.prompt.formatPromptValue(valuesForPrompt);\n    const {\n      generations\n    } = await this.llm.generatePrompt([promptValue], valuesForLLM, runManager?.getChild());\n    return {\n      [this.outputKey]: await this._getFinalOutput(generations[0], promptValue, runManager)\n    };\n  }\n  /**\n   * Format prompt with values and pass to LLM\n   *\n   * @param values - keys to pass to prompt template\n   * @param callbackManager - CallbackManager to use\n   * @returns Completion from LLM.\n   *\n   * @example\n   * ```ts\n   * llm.predict({ adjective: \"funny\" })\n   * ```\n   */\n  async predict(values, callbackManager) {\n    const output = await this.call(values, callbackManager);\n    return output[this.outputKey];\n  }\n  _chainType() {\n    return \"llm\";\n  }\n  static async deserialize(data) {\n    const {\n      llm,\n      prompt\n    } = data;\n    if (!llm) {\n      throw new Error(\"LLMChain must have llm\");\n    }\n    if (!prompt) {\n      throw new Error(\"LLMChain must have prompt\");\n    }\n    return new LLMChain({\n      llm: await BaseLanguageModel.deserialize(llm),\n      prompt: await BasePromptTemplate.deserialize(prompt)\n    });\n  }\n  /** @deprecated */\n  serialize() {\n    return {\n      _type: `${this._chainType()}_chain`,\n      llm: this.llm.serialize(),\n      prompt: this.prompt.serialize()\n    };\n  }\n}","map":{"version":3,"names":["BaseChain","BasePromptTemplate","BaseLanguageModel","NoOpOutputParser","LLMChain","lc_name","inputKeys","prompt","inputVariables","outputKeys","outputKey","constructor","fields","Object","defineProperty","enumerable","configurable","writable","value","llm","llmKwargs","outputParser","Error","_selectMemoryInputs","values","valuesForMemory","key","callKeys","_getFinalOutput","generations","promptValue","runManager","finalCompletion","parseResultWithPrompt","getChild","text","call","config","_call","valuesForPrompt","valuesForLLM","formatPromptValue","generatePrompt","predict","callbackManager","output","_chainType","deserialize","data","serialize","_type"],"sources":["/Users/mayamagavi/instalily/case-study/node_modules/langchain/dist/chains/llm_chain.js"],"sourcesContent":["import { BaseChain } from \"./base.js\";\nimport { BasePromptTemplate } from \"../prompts/base.js\";\nimport { BaseLanguageModel } from \"../base_language/index.js\";\nimport { NoOpOutputParser } from \"../output_parsers/noop.js\";\n/**\n * Chain to run queries against LLMs.\n *\n * @example\n * ```ts\n * import { LLMChain } from \"langchain/chains\";\n * import { OpenAI } from \"langchain/llms/openai\";\n * import { PromptTemplate } from \"langchain/prompts\";\n *\n * const prompt = PromptTemplate.fromTemplate(\"Tell me a {adjective} joke\");\n * const llm = new LLMChain({ llm: new OpenAI(), prompt });\n * ```\n */\nexport class LLMChain extends BaseChain {\n    static lc_name() {\n        return \"LLMChain\";\n    }\n    get inputKeys() {\n        return this.prompt.inputVariables;\n    }\n    get outputKeys() {\n        return [this.outputKey];\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"prompt\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"llm\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"llmKwargs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"outputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"text\"\n        });\n        Object.defineProperty(this, \"outputParser\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.prompt = fields.prompt;\n        this.llm = fields.llm;\n        this.llmKwargs = fields.llmKwargs;\n        this.outputKey = fields.outputKey ?? this.outputKey;\n        this.outputParser =\n            fields.outputParser ?? new NoOpOutputParser();\n        if (this.prompt.outputParser) {\n            if (fields.outputParser) {\n                throw new Error(\"Cannot set both outputParser and prompt.outputParser\");\n            }\n            this.outputParser = this.prompt.outputParser;\n        }\n    }\n    /** @ignore */\n    _selectMemoryInputs(values) {\n        const valuesForMemory = super._selectMemoryInputs(values);\n        for (const key of this.llm.callKeys) {\n            if (key in values) {\n                delete valuesForMemory[key];\n            }\n        }\n        return valuesForMemory;\n    }\n    /** @ignore */\n    async _getFinalOutput(generations, promptValue, runManager) {\n        let finalCompletion;\n        if (this.outputParser) {\n            finalCompletion = await this.outputParser.parseResultWithPrompt(generations, promptValue, runManager?.getChild());\n        }\n        else {\n            finalCompletion = generations[0].text;\n        }\n        return finalCompletion;\n    }\n    /**\n     * Run the core logic of this chain and add to output if desired.\n     *\n     * Wraps _call and handles memory.\n     */\n    call(values, config) {\n        return super.call(values, config);\n    }\n    /** @ignore */\n    async _call(values, runManager) {\n        const valuesForPrompt = { ...values };\n        const valuesForLLM = {\n            ...this.llmKwargs,\n        };\n        for (const key of this.llm.callKeys) {\n            if (key in values) {\n                valuesForLLM[key] = values[key];\n                delete valuesForPrompt[key];\n            }\n        }\n        const promptValue = await this.prompt.formatPromptValue(valuesForPrompt);\n        const { generations } = await this.llm.generatePrompt([promptValue], valuesForLLM, runManager?.getChild());\n        return {\n            [this.outputKey]: await this._getFinalOutput(generations[0], promptValue, runManager),\n        };\n    }\n    /**\n     * Format prompt with values and pass to LLM\n     *\n     * @param values - keys to pass to prompt template\n     * @param callbackManager - CallbackManager to use\n     * @returns Completion from LLM.\n     *\n     * @example\n     * ```ts\n     * llm.predict({ adjective: \"funny\" })\n     * ```\n     */\n    async predict(values, callbackManager) {\n        const output = await this.call(values, callbackManager);\n        return output[this.outputKey];\n    }\n    _chainType() {\n        return \"llm\";\n    }\n    static async deserialize(data) {\n        const { llm, prompt } = data;\n        if (!llm) {\n            throw new Error(\"LLMChain must have llm\");\n        }\n        if (!prompt) {\n            throw new Error(\"LLMChain must have prompt\");\n        }\n        return new LLMChain({\n            llm: await BaseLanguageModel.deserialize(llm),\n            prompt: await BasePromptTemplate.deserialize(prompt),\n        });\n    }\n    /** @deprecated */\n    serialize() {\n        return {\n            _type: `${this._chainType()}_chain`,\n            llm: this.llm.serialize(),\n            prompt: this.prompt.serialize(),\n        };\n    }\n}\n"],"mappings":"AAAA,SAASA,SAAS,QAAQ,WAAW;AACrC,SAASC,kBAAkB,QAAQ,oBAAoB;AACvD,SAASC,iBAAiB,QAAQ,2BAA2B;AAC7D,SAASC,gBAAgB,QAAQ,2BAA2B;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,QAAQ,SAASJ,SAAS,CAAC;EACpC,OAAOK,OAAOA,CAAA,EAAG;IACb,OAAO,UAAU;EACrB;EACA,IAAIC,SAASA,CAAA,EAAG;IACZ,OAAO,IAAI,CAACC,MAAM,CAACC,cAAc;EACrC;EACA,IAAIC,UAAUA,CAAA,EAAG;IACb,OAAO,CAAC,IAAI,CAACC,SAAS,CAAC;EAC3B;EACAC,WAAWA,CAACC,MAAM,EAAE;IAChB,KAAK,CAACA,MAAM,CAAC;IACbC,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,iBAAiB,EAAE;MAC3CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,QAAQ,EAAE;MAClCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,KAAK,EAAE;MAC/BC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,cAAc,EAAE;MACxCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACF,IAAI,CAACX,MAAM,GAAGK,MAAM,CAACL,MAAM;IAC3B,IAAI,CAACY,GAAG,GAAGP,MAAM,CAACO,GAAG;IACrB,IAAI,CAACC,SAAS,GAAGR,MAAM,CAACQ,SAAS;IACjC,IAAI,CAACV,SAAS,GAAGE,MAAM,CAACF,SAAS,IAAI,IAAI,CAACA,SAAS;IACnD,IAAI,CAACW,YAAY,GACbT,MAAM,CAACS,YAAY,IAAI,IAAIlB,gBAAgB,CAAC,CAAC;IACjD,IAAI,IAAI,CAACI,MAAM,CAACc,YAAY,EAAE;MAC1B,IAAIT,MAAM,CAACS,YAAY,EAAE;QACrB,MAAM,IAAIC,KAAK,CAAC,sDAAsD,CAAC;MAC3E;MACA,IAAI,CAACD,YAAY,GAAG,IAAI,CAACd,MAAM,CAACc,YAAY;IAChD;EACJ;EACA;EACAE,mBAAmBA,CAACC,MAAM,EAAE;IACxB,MAAMC,eAAe,GAAG,KAAK,CAACF,mBAAmB,CAACC,MAAM,CAAC;IACzD,KAAK,MAAME,GAAG,IAAI,IAAI,CAACP,GAAG,CAACQ,QAAQ,EAAE;MACjC,IAAID,GAAG,IAAIF,MAAM,EAAE;QACf,OAAOC,eAAe,CAACC,GAAG,CAAC;MAC/B;IACJ;IACA,OAAOD,eAAe;EAC1B;EACA;EACA,MAAMG,eAAeA,CAACC,WAAW,EAAEC,WAAW,EAAEC,UAAU,EAAE;IACxD,IAAIC,eAAe;IACnB,IAAI,IAAI,CAACX,YAAY,EAAE;MACnBW,eAAe,GAAG,MAAM,IAAI,CAACX,YAAY,CAACY,qBAAqB,CAACJ,WAAW,EAAEC,WAAW,EAAEC,UAAU,EAAEG,QAAQ,CAAC,CAAC,CAAC;IACrH,CAAC,MACI;MACDF,eAAe,GAAGH,WAAW,CAAC,CAAC,CAAC,CAACM,IAAI;IACzC;IACA,OAAOH,eAAe;EAC1B;EACA;AACJ;AACA;AACA;AACA;EACII,IAAIA,CAACZ,MAAM,EAAEa,MAAM,EAAE;IACjB,OAAO,KAAK,CAACD,IAAI,CAACZ,MAAM,EAAEa,MAAM,CAAC;EACrC;EACA;EACA,MAAMC,KAAKA,CAACd,MAAM,EAAEO,UAAU,EAAE;IAC5B,MAAMQ,eAAe,GAAG;MAAE,GAAGf;IAAO,CAAC;IACrC,MAAMgB,YAAY,GAAG;MACjB,GAAG,IAAI,CAACpB;IACZ,CAAC;IACD,KAAK,MAAMM,GAAG,IAAI,IAAI,CAACP,GAAG,CAACQ,QAAQ,EAAE;MACjC,IAAID,GAAG,IAAIF,MAAM,EAAE;QACfgB,YAAY,CAACd,GAAG,CAAC,GAAGF,MAAM,CAACE,GAAG,CAAC;QAC/B,OAAOa,eAAe,CAACb,GAAG,CAAC;MAC/B;IACJ;IACA,MAAMI,WAAW,GAAG,MAAM,IAAI,CAACvB,MAAM,CAACkC,iBAAiB,CAACF,eAAe,CAAC;IACxE,MAAM;MAAEV;IAAY,CAAC,GAAG,MAAM,IAAI,CAACV,GAAG,CAACuB,cAAc,CAAC,CAACZ,WAAW,CAAC,EAAEU,YAAY,EAAET,UAAU,EAAEG,QAAQ,CAAC,CAAC,CAAC;IAC1G,OAAO;MACH,CAAC,IAAI,CAACxB,SAAS,GAAG,MAAM,IAAI,CAACkB,eAAe,CAACC,WAAW,CAAC,CAAC,CAAC,EAAEC,WAAW,EAAEC,UAAU;IACxF,CAAC;EACL;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,MAAMY,OAAOA,CAACnB,MAAM,EAAEoB,eAAe,EAAE;IACnC,MAAMC,MAAM,GAAG,MAAM,IAAI,CAACT,IAAI,CAACZ,MAAM,EAAEoB,eAAe,CAAC;IACvD,OAAOC,MAAM,CAAC,IAAI,CAACnC,SAAS,CAAC;EACjC;EACAoC,UAAUA,CAAA,EAAG;IACT,OAAO,KAAK;EAChB;EACA,aAAaC,WAAWA,CAACC,IAAI,EAAE;IAC3B,MAAM;MAAE7B,GAAG;MAAEZ;IAAO,CAAC,GAAGyC,IAAI;IAC5B,IAAI,CAAC7B,GAAG,EAAE;MACN,MAAM,IAAIG,KAAK,CAAC,wBAAwB,CAAC;IAC7C;IACA,IAAI,CAACf,MAAM,EAAE;MACT,MAAM,IAAIe,KAAK,CAAC,2BAA2B,CAAC;IAChD;IACA,OAAO,IAAIlB,QAAQ,CAAC;MAChBe,GAAG,EAAE,MAAMjB,iBAAiB,CAAC6C,WAAW,CAAC5B,GAAG,CAAC;MAC7CZ,MAAM,EAAE,MAAMN,kBAAkB,CAAC8C,WAAW,CAACxC,MAAM;IACvD,CAAC,CAAC;EACN;EACA;EACA0C,SAASA,CAAA,EAAG;IACR,OAAO;MACHC,KAAK,EAAG,GAAE,IAAI,CAACJ,UAAU,CAAC,CAAE,QAAO;MACnC3B,GAAG,EAAE,IAAI,CAACA,GAAG,CAAC8B,SAAS,CAAC,CAAC;MACzB1C,MAAM,EAAE,IAAI,CAACA,MAAM,CAAC0C,SAAS,CAAC;IAClC,CAAC;EACL;AACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}