{"ast":null,"code":"import { PromptTemplate } from \"../prompts/prompt.js\";\nimport { HumanMessage, AIMessage } from \"../schema/index.js\";\nimport { BaseChain } from \"./base.js\";\nimport { LLMChain } from \"./llm_chain.js\";\nimport { loadQAChain } from \"./question_answering/load.js\";\nconst question_generator_template = `Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone question:`;\n/**\n * Class for conducting conversational question-answering tasks with a\n * retrieval component. Extends the BaseChain class and implements the\n * ConversationalRetrievalQAChainInput interface.\n */\nexport class ConversationalRetrievalQAChain extends BaseChain {\n  static lc_name() {\n    return \"ConversationalRetrievalQAChain\";\n  }\n  get inputKeys() {\n    return [this.inputKey, this.chatHistoryKey];\n  }\n  get outputKeys() {\n    return this.combineDocumentsChain.outputKeys.concat(this.returnSourceDocuments ? [\"sourceDocuments\"] : []);\n  }\n  constructor(fields) {\n    super(fields);\n    Object.defineProperty(this, \"inputKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: \"question\"\n    });\n    Object.defineProperty(this, \"chatHistoryKey\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: \"chat_history\"\n    });\n    Object.defineProperty(this, \"retriever\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"combineDocumentsChain\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"questionGeneratorChain\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: void 0\n    });\n    Object.defineProperty(this, \"returnSourceDocuments\", {\n      enumerable: true,\n      configurable: true,\n      writable: true,\n      value: false\n    });\n    this.retriever = fields.retriever;\n    this.combineDocumentsChain = fields.combineDocumentsChain;\n    this.questionGeneratorChain = fields.questionGeneratorChain;\n    this.inputKey = fields.inputKey ?? this.inputKey;\n    this.returnSourceDocuments = fields.returnSourceDocuments ?? this.returnSourceDocuments;\n  }\n  /**\n   * Static method to convert the chat history input into a formatted\n   * string.\n   * @param chatHistory Chat history input which can be a string, an array of BaseMessage instances, or an array of string arrays.\n   * @returns A formatted string representing the chat history.\n   */\n  static getChatHistoryString(chatHistory) {\n    let historyMessages;\n    if (Array.isArray(chatHistory)) {\n      // TODO: Deprecate on a breaking release\n      if (Array.isArray(chatHistory[0]) && typeof chatHistory[0][0] === \"string\") {\n        console.warn(\"Passing chat history as an array of strings is deprecated.\\nPlease see https://js.langchain.com/docs/modules/chains/popular/chat_vector_db#externally-managed-memory for more information.\");\n        historyMessages = chatHistory.flat().map((stringMessage, i) => {\n          if (i % 2 === 0) {\n            return new HumanMessage(stringMessage);\n          } else {\n            return new AIMessage(stringMessage);\n          }\n        });\n      } else {\n        historyMessages = chatHistory;\n      }\n      return historyMessages.map(chatMessage => {\n        if (chatMessage._getType() === \"human\") {\n          return `Human: ${chatMessage.content}`;\n        } else if (chatMessage._getType() === \"ai\") {\n          return `Assistant: ${chatMessage.content}`;\n        } else {\n          return `${chatMessage.content}`;\n        }\n      }).join(\"\\n\");\n    }\n    return chatHistory;\n  }\n  /** @ignore */\n  async _call(values, runManager) {\n    if (!(this.inputKey in values)) {\n      throw new Error(`Question key ${this.inputKey} not found.`);\n    }\n    if (!(this.chatHistoryKey in values)) {\n      throw new Error(`Chat history key ${this.chatHistoryKey} not found.`);\n    }\n    const question = values[this.inputKey];\n    const chatHistory = ConversationalRetrievalQAChain.getChatHistoryString(values[this.chatHistoryKey]);\n    let newQuestion = question;\n    if (chatHistory.length > 0) {\n      const result = await this.questionGeneratorChain.call({\n        question,\n        chat_history: chatHistory\n      }, runManager?.getChild(\"question_generator\"));\n      const keys = Object.keys(result);\n      if (keys.length === 1) {\n        newQuestion = result[keys[0]];\n      } else {\n        throw new Error(\"Return from llm chain has multiple values, only single values supported.\");\n      }\n    }\n    const docs = await this.retriever.getRelevantDocuments(newQuestion, runManager?.getChild(\"retriever\"));\n    const inputs = {\n      question: newQuestion,\n      input_documents: docs,\n      chat_history: chatHistory\n    };\n    const result = await this.combineDocumentsChain.call(inputs, runManager?.getChild(\"combine_documents\"));\n    if (this.returnSourceDocuments) {\n      return {\n        ...result,\n        sourceDocuments: docs\n      };\n    }\n    return result;\n  }\n  _chainType() {\n    return \"conversational_retrieval_chain\";\n  }\n  static async deserialize(_data, _values) {\n    throw new Error(\"Not implemented.\");\n  }\n  serialize() {\n    throw new Error(\"Not implemented.\");\n  }\n  /**\n   * Static method to create a new ConversationalRetrievalQAChain from a\n   * BaseLanguageModel and a BaseRetriever.\n   * @param llm {@link BaseLanguageModel} instance used to generate a new question.\n   * @param retriever {@link BaseRetriever} instance used to retrieve relevant documents.\n   * @param options.returnSourceDocuments Whether to return source documents in the final output\n   * @param options.questionGeneratorChainOptions Options to initialize the standalone question generation chain used as the first internal step\n   * @param options.qaChainOptions {@link QAChainParams} used to initialize the QA chain used as the second internal step\n   * @returns A new instance of ConversationalRetrievalQAChain.\n   */\n  static fromLLM(llm, retriever, options = {}) {\n    const {\n      questionGeneratorTemplate,\n      qaTemplate,\n      qaChainOptions = {\n        type: \"stuff\",\n        prompt: qaTemplate ? PromptTemplate.fromTemplate(qaTemplate) : undefined\n      },\n      questionGeneratorChainOptions,\n      verbose,\n      ...rest\n    } = options;\n    const qaChain = loadQAChain(llm, qaChainOptions);\n    const questionGeneratorChainPrompt = PromptTemplate.fromTemplate(questionGeneratorChainOptions?.template ?? questionGeneratorTemplate ?? question_generator_template);\n    const questionGeneratorChain = new LLMChain({\n      prompt: questionGeneratorChainPrompt,\n      llm: questionGeneratorChainOptions?.llm ?? llm,\n      verbose\n    });\n    const instance = new this({\n      retriever,\n      combineDocumentsChain: qaChain,\n      questionGeneratorChain,\n      verbose,\n      ...rest\n    });\n    return instance;\n  }\n}","map":{"version":3,"names":["PromptTemplate","HumanMessage","AIMessage","BaseChain","LLMChain","loadQAChain","question_generator_template","ConversationalRetrievalQAChain","lc_name","inputKeys","inputKey","chatHistoryKey","outputKeys","combineDocumentsChain","concat","returnSourceDocuments","constructor","fields","Object","defineProperty","enumerable","configurable","writable","value","retriever","questionGeneratorChain","getChatHistoryString","chatHistory","historyMessages","Array","isArray","console","warn","flat","map","stringMessage","i","chatMessage","_getType","content","join","_call","values","runManager","Error","question","newQuestion","length","result","call","chat_history","getChild","keys","docs","getRelevantDocuments","inputs","input_documents","sourceDocuments","_chainType","deserialize","_data","_values","serialize","fromLLM","llm","options","questionGeneratorTemplate","qaTemplate","qaChainOptions","type","prompt","fromTemplate","undefined","questionGeneratorChainOptions","verbose","rest","qaChain","questionGeneratorChainPrompt","template","instance"],"sources":["/Users/mayamagavi/instalily/case-study/node_modules/langchain/dist/chains/conversational_retrieval_chain.js"],"sourcesContent":["import { PromptTemplate } from \"../prompts/prompt.js\";\nimport { HumanMessage, AIMessage, } from \"../schema/index.js\";\nimport { BaseChain } from \"./base.js\";\nimport { LLMChain } from \"./llm_chain.js\";\nimport { loadQAChain } from \"./question_answering/load.js\";\nconst question_generator_template = `Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone question:`;\n/**\n * Class for conducting conversational question-answering tasks with a\n * retrieval component. Extends the BaseChain class and implements the\n * ConversationalRetrievalQAChainInput interface.\n */\nexport class ConversationalRetrievalQAChain extends BaseChain {\n    static lc_name() {\n        return \"ConversationalRetrievalQAChain\";\n    }\n    get inputKeys() {\n        return [this.inputKey, this.chatHistoryKey];\n    }\n    get outputKeys() {\n        return this.combineDocumentsChain.outputKeys.concat(this.returnSourceDocuments ? [\"sourceDocuments\"] : []);\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"inputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"question\"\n        });\n        Object.defineProperty(this, \"chatHistoryKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"chat_history\"\n        });\n        Object.defineProperty(this, \"retriever\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"combineDocumentsChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"questionGeneratorChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"returnSourceDocuments\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        this.retriever = fields.retriever;\n        this.combineDocumentsChain = fields.combineDocumentsChain;\n        this.questionGeneratorChain = fields.questionGeneratorChain;\n        this.inputKey = fields.inputKey ?? this.inputKey;\n        this.returnSourceDocuments =\n            fields.returnSourceDocuments ?? this.returnSourceDocuments;\n    }\n    /**\n     * Static method to convert the chat history input into a formatted\n     * string.\n     * @param chatHistory Chat history input which can be a string, an array of BaseMessage instances, or an array of string arrays.\n     * @returns A formatted string representing the chat history.\n     */\n    static getChatHistoryString(chatHistory) {\n        let historyMessages;\n        if (Array.isArray(chatHistory)) {\n            // TODO: Deprecate on a breaking release\n            if (Array.isArray(chatHistory[0]) &&\n                typeof chatHistory[0][0] === \"string\") {\n                console.warn(\"Passing chat history as an array of strings is deprecated.\\nPlease see https://js.langchain.com/docs/modules/chains/popular/chat_vector_db#externally-managed-memory for more information.\");\n                historyMessages = chatHistory.flat().map((stringMessage, i) => {\n                    if (i % 2 === 0) {\n                        return new HumanMessage(stringMessage);\n                    }\n                    else {\n                        return new AIMessage(stringMessage);\n                    }\n                });\n            }\n            else {\n                historyMessages = chatHistory;\n            }\n            return historyMessages\n                .map((chatMessage) => {\n                if (chatMessage._getType() === \"human\") {\n                    return `Human: ${chatMessage.content}`;\n                }\n                else if (chatMessage._getType() === \"ai\") {\n                    return `Assistant: ${chatMessage.content}`;\n                }\n                else {\n                    return `${chatMessage.content}`;\n                }\n            })\n                .join(\"\\n\");\n        }\n        return chatHistory;\n    }\n    /** @ignore */\n    async _call(values, runManager) {\n        if (!(this.inputKey in values)) {\n            throw new Error(`Question key ${this.inputKey} not found.`);\n        }\n        if (!(this.chatHistoryKey in values)) {\n            throw new Error(`Chat history key ${this.chatHistoryKey} not found.`);\n        }\n        const question = values[this.inputKey];\n        const chatHistory = ConversationalRetrievalQAChain.getChatHistoryString(values[this.chatHistoryKey]);\n        let newQuestion = question;\n        if (chatHistory.length > 0) {\n            const result = await this.questionGeneratorChain.call({\n                question,\n                chat_history: chatHistory,\n            }, runManager?.getChild(\"question_generator\"));\n            const keys = Object.keys(result);\n            if (keys.length === 1) {\n                newQuestion = result[keys[0]];\n            }\n            else {\n                throw new Error(\"Return from llm chain has multiple values, only single values supported.\");\n            }\n        }\n        const docs = await this.retriever.getRelevantDocuments(newQuestion, runManager?.getChild(\"retriever\"));\n        const inputs = {\n            question: newQuestion,\n            input_documents: docs,\n            chat_history: chatHistory,\n        };\n        const result = await this.combineDocumentsChain.call(inputs, runManager?.getChild(\"combine_documents\"));\n        if (this.returnSourceDocuments) {\n            return {\n                ...result,\n                sourceDocuments: docs,\n            };\n        }\n        return result;\n    }\n    _chainType() {\n        return \"conversational_retrieval_chain\";\n    }\n    static async deserialize(_data, _values) {\n        throw new Error(\"Not implemented.\");\n    }\n    serialize() {\n        throw new Error(\"Not implemented.\");\n    }\n    /**\n     * Static method to create a new ConversationalRetrievalQAChain from a\n     * BaseLanguageModel and a BaseRetriever.\n     * @param llm {@link BaseLanguageModel} instance used to generate a new question.\n     * @param retriever {@link BaseRetriever} instance used to retrieve relevant documents.\n     * @param options.returnSourceDocuments Whether to return source documents in the final output\n     * @param options.questionGeneratorChainOptions Options to initialize the standalone question generation chain used as the first internal step\n     * @param options.qaChainOptions {@link QAChainParams} used to initialize the QA chain used as the second internal step\n     * @returns A new instance of ConversationalRetrievalQAChain.\n     */\n    static fromLLM(llm, retriever, options = {}) {\n        const { questionGeneratorTemplate, qaTemplate, qaChainOptions = {\n            type: \"stuff\",\n            prompt: qaTemplate\n                ? PromptTemplate.fromTemplate(qaTemplate)\n                : undefined,\n        }, questionGeneratorChainOptions, verbose, ...rest } = options;\n        const qaChain = loadQAChain(llm, qaChainOptions);\n        const questionGeneratorChainPrompt = PromptTemplate.fromTemplate(questionGeneratorChainOptions?.template ??\n            questionGeneratorTemplate ??\n            question_generator_template);\n        const questionGeneratorChain = new LLMChain({\n            prompt: questionGeneratorChainPrompt,\n            llm: questionGeneratorChainOptions?.llm ?? llm,\n            verbose,\n        });\n        const instance = new this({\n            retriever,\n            combineDocumentsChain: qaChain,\n            questionGeneratorChain,\n            verbose,\n            ...rest,\n        });\n        return instance;\n    }\n}\n"],"mappings":"AAAA,SAASA,cAAc,QAAQ,sBAAsB;AACrD,SAASC,YAAY,EAAEC,SAAS,QAAS,oBAAoB;AAC7D,SAASC,SAAS,QAAQ,WAAW;AACrC,SAASC,QAAQ,QAAQ,gBAAgB;AACzC,SAASC,WAAW,QAAQ,8BAA8B;AAC1D,MAAMC,2BAA2B,GAAI;AACrC;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,8BAA8B,SAASJ,SAAS,CAAC;EAC1D,OAAOK,OAAOA,CAAA,EAAG;IACb,OAAO,gCAAgC;EAC3C;EACA,IAAIC,SAASA,CAAA,EAAG;IACZ,OAAO,CAAC,IAAI,CAACC,QAAQ,EAAE,IAAI,CAACC,cAAc,CAAC;EAC/C;EACA,IAAIC,UAAUA,CAAA,EAAG;IACb,OAAO,IAAI,CAACC,qBAAqB,CAACD,UAAU,CAACE,MAAM,CAAC,IAAI,CAACC,qBAAqB,GAAG,CAAC,iBAAiB,CAAC,GAAG,EAAE,CAAC;EAC9G;EACAC,WAAWA,CAACC,MAAM,EAAE;IAChB,KAAK,CAACA,MAAM,CAAC;IACbC,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,UAAU,EAAE;MACpCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,gBAAgB,EAAE;MAC1CC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,WAAW,EAAE;MACrCC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,uBAAuB,EAAE;MACjDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,wBAAwB,EAAE;MAClDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE,KAAK;IAChB,CAAC,CAAC;IACFL,MAAM,CAACC,cAAc,CAAC,IAAI,EAAE,uBAAuB,EAAE;MACjDC,UAAU,EAAE,IAAI;MAChBC,YAAY,EAAE,IAAI;MAClBC,QAAQ,EAAE,IAAI;MACdC,KAAK,EAAE;IACX,CAAC,CAAC;IACF,IAAI,CAACC,SAAS,GAAGP,MAAM,CAACO,SAAS;IACjC,IAAI,CAACX,qBAAqB,GAAGI,MAAM,CAACJ,qBAAqB;IACzD,IAAI,CAACY,sBAAsB,GAAGR,MAAM,CAACQ,sBAAsB;IAC3D,IAAI,CAACf,QAAQ,GAAGO,MAAM,CAACP,QAAQ,IAAI,IAAI,CAACA,QAAQ;IAChD,IAAI,CAACK,qBAAqB,GACtBE,MAAM,CAACF,qBAAqB,IAAI,IAAI,CAACA,qBAAqB;EAClE;EACA;AACJ;AACA;AACA;AACA;AACA;EACI,OAAOW,oBAAoBA,CAACC,WAAW,EAAE;IACrC,IAAIC,eAAe;IACnB,IAAIC,KAAK,CAACC,OAAO,CAACH,WAAW,CAAC,EAAE;MAC5B;MACA,IAAIE,KAAK,CAACC,OAAO,CAACH,WAAW,CAAC,CAAC,CAAC,CAAC,IAC7B,OAAOA,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,KAAK,QAAQ,EAAE;QACvCI,OAAO,CAACC,IAAI,CAAC,4LAA4L,CAAC;QAC1MJ,eAAe,GAAGD,WAAW,CAACM,IAAI,CAAC,CAAC,CAACC,GAAG,CAAC,CAACC,aAAa,EAAEC,CAAC,KAAK;UAC3D,IAAIA,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE;YACb,OAAO,IAAInC,YAAY,CAACkC,aAAa,CAAC;UAC1C,CAAC,MACI;YACD,OAAO,IAAIjC,SAAS,CAACiC,aAAa,CAAC;UACvC;QACJ,CAAC,CAAC;MACN,CAAC,MACI;QACDP,eAAe,GAAGD,WAAW;MACjC;MACA,OAAOC,eAAe,CACjBM,GAAG,CAAEG,WAAW,IAAK;QACtB,IAAIA,WAAW,CAACC,QAAQ,CAAC,CAAC,KAAK,OAAO,EAAE;UACpC,OAAQ,UAASD,WAAW,CAACE,OAAQ,EAAC;QAC1C,CAAC,MACI,IAAIF,WAAW,CAACC,QAAQ,CAAC,CAAC,KAAK,IAAI,EAAE;UACtC,OAAQ,cAAaD,WAAW,CAACE,OAAQ,EAAC;QAC9C,CAAC,MACI;UACD,OAAQ,GAAEF,WAAW,CAACE,OAAQ,EAAC;QACnC;MACJ,CAAC,CAAC,CACGC,IAAI,CAAC,IAAI,CAAC;IACnB;IACA,OAAOb,WAAW;EACtB;EACA;EACA,MAAMc,KAAKA,CAACC,MAAM,EAAEC,UAAU,EAAE;IAC5B,IAAI,EAAE,IAAI,CAACjC,QAAQ,IAAIgC,MAAM,CAAC,EAAE;MAC5B,MAAM,IAAIE,KAAK,CAAE,gBAAe,IAAI,CAAClC,QAAS,aAAY,CAAC;IAC/D;IACA,IAAI,EAAE,IAAI,CAACC,cAAc,IAAI+B,MAAM,CAAC,EAAE;MAClC,MAAM,IAAIE,KAAK,CAAE,oBAAmB,IAAI,CAACjC,cAAe,aAAY,CAAC;IACzE;IACA,MAAMkC,QAAQ,GAAGH,MAAM,CAAC,IAAI,CAAChC,QAAQ,CAAC;IACtC,MAAMiB,WAAW,GAAGpB,8BAA8B,CAACmB,oBAAoB,CAACgB,MAAM,CAAC,IAAI,CAAC/B,cAAc,CAAC,CAAC;IACpG,IAAImC,WAAW,GAAGD,QAAQ;IAC1B,IAAIlB,WAAW,CAACoB,MAAM,GAAG,CAAC,EAAE;MACxB,MAAMC,MAAM,GAAG,MAAM,IAAI,CAACvB,sBAAsB,CAACwB,IAAI,CAAC;QAClDJ,QAAQ;QACRK,YAAY,EAAEvB;MAClB,CAAC,EAAEgB,UAAU,EAAEQ,QAAQ,CAAC,oBAAoB,CAAC,CAAC;MAC9C,MAAMC,IAAI,GAAGlC,MAAM,CAACkC,IAAI,CAACJ,MAAM,CAAC;MAChC,IAAII,IAAI,CAACL,MAAM,KAAK,CAAC,EAAE;QACnBD,WAAW,GAAGE,MAAM,CAACI,IAAI,CAAC,CAAC,CAAC,CAAC;MACjC,CAAC,MACI;QACD,MAAM,IAAIR,KAAK,CAAC,0EAA0E,CAAC;MAC/F;IACJ;IACA,MAAMS,IAAI,GAAG,MAAM,IAAI,CAAC7B,SAAS,CAAC8B,oBAAoB,CAACR,WAAW,EAAEH,UAAU,EAAEQ,QAAQ,CAAC,WAAW,CAAC,CAAC;IACtG,MAAMI,MAAM,GAAG;MACXV,QAAQ,EAAEC,WAAW;MACrBU,eAAe,EAAEH,IAAI;MACrBH,YAAY,EAAEvB;IAClB,CAAC;IACD,MAAMqB,MAAM,GAAG,MAAM,IAAI,CAACnC,qBAAqB,CAACoC,IAAI,CAACM,MAAM,EAAEZ,UAAU,EAAEQ,QAAQ,CAAC,mBAAmB,CAAC,CAAC;IACvG,IAAI,IAAI,CAACpC,qBAAqB,EAAE;MAC5B,OAAO;QACH,GAAGiC,MAAM;QACTS,eAAe,EAAEJ;MACrB,CAAC;IACL;IACA,OAAOL,MAAM;EACjB;EACAU,UAAUA,CAAA,EAAG;IACT,OAAO,gCAAgC;EAC3C;EACA,aAAaC,WAAWA,CAACC,KAAK,EAAEC,OAAO,EAAE;IACrC,MAAM,IAAIjB,KAAK,CAAC,kBAAkB,CAAC;EACvC;EACAkB,SAASA,CAAA,EAAG;IACR,MAAM,IAAIlB,KAAK,CAAC,kBAAkB,CAAC;EACvC;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,OAAOmB,OAAOA,CAACC,GAAG,EAAExC,SAAS,EAAEyC,OAAO,GAAG,CAAC,CAAC,EAAE;IACzC,MAAM;MAAEC,yBAAyB;MAAEC,UAAU;MAAEC,cAAc,GAAG;QAC5DC,IAAI,EAAE,OAAO;QACbC,MAAM,EAAEH,UAAU,GACZnE,cAAc,CAACuE,YAAY,CAACJ,UAAU,CAAC,GACvCK;MACV,CAAC;MAAEC,6BAA6B;MAAEC,OAAO;MAAE,GAAGC;IAAK,CAAC,GAAGV,OAAO;IAC9D,MAAMW,OAAO,GAAGvE,WAAW,CAAC2D,GAAG,EAAEI,cAAc,CAAC;IAChD,MAAMS,4BAA4B,GAAG7E,cAAc,CAACuE,YAAY,CAACE,6BAA6B,EAAEK,QAAQ,IACpGZ,yBAAyB,IACzB5D,2BAA2B,CAAC;IAChC,MAAMmB,sBAAsB,GAAG,IAAIrB,QAAQ,CAAC;MACxCkE,MAAM,EAAEO,4BAA4B;MACpCb,GAAG,EAAES,6BAA6B,EAAET,GAAG,IAAIA,GAAG;MAC9CU;IACJ,CAAC,CAAC;IACF,MAAMK,QAAQ,GAAG,IAAI,IAAI,CAAC;MACtBvD,SAAS;MACTX,qBAAqB,EAAE+D,OAAO;MAC9BnD,sBAAsB;MACtBiD,OAAO;MACP,GAAGC;IACP,CAAC,CAAC;IACF,OAAOI,QAAQ;EACnB;AACJ"},"metadata":{},"sourceType":"module","externalDependencies":[]}